{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,f1_score\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_11604\\413425515.py:2: DtypeWarning: Columns (65,76,91,154,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"train_data.csv\", index_col=0).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Relevant seasons:  [1718 1819 1920 2021 2122]\n",
      "Modified seasons:  [17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "# Read the entire dataset\n",
    "df = pd.read_csv(\"train_data.csv\", index_col=0).reset_index(drop=True)\n",
    "\n",
    "# Set the number of last x relevant seasons\n",
    "last_seasons = 5\n",
    "# Check for NA in seasons\n",
    "print(df[\"season\"].isna().sum())\n",
    "\n",
    "# Find relevant seasons\n",
    "relevant_seasons = df[\"season\"].unique()[-last_seasons:]\n",
    "print(\"Relevant seasons: \", relevant_seasons)\n",
    "\n",
    "# Filter out relevant seasons from DF\n",
    "df = df.loc[df[\"season\"].isin(relevant_seasons) , :]\n",
    "\n",
    "# Modify the season format for better data manipulation\n",
    "df[\"season\"] = df[\"season\"].apply(lambda x: int(str(x)[:2]))\n",
    "print(\"Modified seasons: \", df[\"season\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27212.000000\n",
       "mean         2.647933\n",
       "std          1.674930\n",
       "min          0.000000\n",
       "25%          1.800000\n",
       "50%          2.250000\n",
       "75%          2.870000\n",
       "max         32.333333\n",
       "Name: AvgHomeOdds, dtype: float64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"AvgHomeOdds\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>SJD</th>\n",
       "      <th>SYD</th>\n",
       "      <th>SYA</th>\n",
       "      <th>GB&gt;2.5</th>\n",
       "      <th>GB&lt;2.5</th>\n",
       "      <th>GBAHH</th>\n",
       "      <th>GBAHA</th>\n",
       "      <th>GBAH</th>\n",
       "      <th>B365AH</th>\n",
       "      <th>SJH</th>\n",
       "      <th>SJA</th>\n",
       "      <th>SOD</th>\n",
       "      <th>BSH</th>\n",
       "      <th>BSD</th>\n",
       "      <th>BSA</th>\n",
       "      <th>SOH</th>\n",
       "      <th>HBP</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>HHW</th>\n",
       "      <th>AHW</th>\n",
       "      <th>HO</th>\n",
       "      <th>SYH</th>\n",
       "      <th>ABP</th>\n",
       "      <th>SOA</th>\n",
       "      <th>GBA</th>\n",
       "      <th>HT</th>\n",
       "      <th>LB.2</th>\n",
       "      <th>LB.1</th>\n",
       "      <th>LB</th>\n",
       "      <th>LBAHH</th>\n",
       "      <th>LBAH</th>\n",
       "      <th>LBAHA</th>\n",
       "      <th>GBH</th>\n",
       "      <th>GBD</th>\n",
       "      <th>AO</th>\n",
       "      <th>SBA</th>\n",
       "      <th>SBH</th>\n",
       "      <th>SBD</th>\n",
       "      <th>AFKC</th>\n",
       "      <th>HFKC</th>\n",
       "      <th>LBH</th>\n",
       "      <th>LBD</th>\n",
       "      <th>LBA</th>\n",
       "      <th>Referee</th>\n",
       "      <th>BbMxH</th>\n",
       "      <th>Bb1X2</th>\n",
       "      <th>BbAv&gt;2.5</th>\n",
       "      <th>BbAH</th>\n",
       "      <th>BbAvAHH</th>\n",
       "      <th>BbAvH</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbMxAHH</th>\n",
       "      <th>BbAvAHA</th>\n",
       "      <th>BbMxD</th>\n",
       "      <th>BbAvD</th>\n",
       "      <th>BbMxA</th>\n",
       "      <th>BbAvA</th>\n",
       "      <th>BbOU</th>\n",
       "      <th>BbMx&gt;2.5</th>\n",
       "      <th>BbMx&lt;2.5</th>\n",
       "      <th>BbAv&lt;2.5</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>P&lt;2.5</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>P&gt;2.5</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>AHh</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>Avg&gt;2.5</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>Max&gt;2.5</th>\n",
       "      <th>Max&lt;2.5</th>\n",
       "      <th>Avg&lt;2.5</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>Time</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSA</th>\n",
       "      <th>PSD</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>BWH</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365D</th>\n",
       "      <th>IWD</th>\n",
       "      <th>B365H</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>AR</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HST</th>\n",
       "      <th>HC</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>AST</th>\n",
       "      <th>HY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AY</th>\n",
       "      <th>Date</th>\n",
       "      <th>AC</th>\n",
       "      <th>AS</th>\n",
       "      <th>HS</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>season</th>\n",
       "      <th>league</th>\n",
       "      <th>country</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96227</td>\n",
       "      <td>0.96227</td>\n",
       "      <td>0.797885</td>\n",
       "      <td>0.797625</td>\n",
       "      <td>0.79751</td>\n",
       "      <td>0.62102</td>\n",
       "      <td>0.593979</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>0.593662</td>\n",
       "      <td>0.593459</td>\n",
       "      <td>0.593459</td>\n",
       "      <td>0.593459</td>\n",
       "      <td>0.593402</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>0.414312</td>\n",
       "      <td>0.413937</td>\n",
       "      <td>0.413937</td>\n",
       "      <td>0.413388</td>\n",
       "      <td>0.413359</td>\n",
       "      <td>0.41203</td>\n",
       "      <td>0.411568</td>\n",
       "      <td>0.41151</td>\n",
       "      <td>0.41151</td>\n",
       "      <td>0.41151</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>0.41099</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>0.409979</td>\n",
       "      <td>0.409776</td>\n",
       "      <td>0.409776</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.409083</td>\n",
       "      <td>0.408939</td>\n",
       "      <td>0.408939</td>\n",
       "      <td>0.408765</td>\n",
       "      <td>0.40865</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.408592</td>\n",
       "      <td>0.408563</td>\n",
       "      <td>0.408505</td>\n",
       "      <td>0.408419</td>\n",
       "      <td>0.408361</td>\n",
       "      <td>0.408303</td>\n",
       "      <td>0.408245</td>\n",
       "      <td>0.408245</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.408101</td>\n",
       "      <td>0.408072</td>\n",
       "      <td>0.408072</td>\n",
       "      <td>0.408072</td>\n",
       "      <td>0.408014</td>\n",
       "      <td>0.407956</td>\n",
       "      <td>0.407956</td>\n",
       "      <td>0.407956</td>\n",
       "      <td>0.40787</td>\n",
       "      <td>0.40787</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.407812</td>\n",
       "      <td>0.407812</td>\n",
       "      <td>0.407725</td>\n",
       "      <td>0.407696</td>\n",
       "      <td>0.40761</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AT  SJD  SYD  SYA  GB>2.5  GB<2.5  GBAHH  GBAHA  GBAH  B365AH  SJH  SJA  \\\n",
       "0  1.0  1.0  1.0  1.0     1.0     1.0    1.0    1.0   1.0     1.0  1.0  1.0   \n",
       "\n",
       "   SOD  BSH  BSD  BSA  SOH  HBP  Attendance  HHW  AHW   HO  SYH  ABP  SOA  \\\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0         1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "\n",
       "   GBA   HT  LB.2  LB.1   LB  LBAHH  LBAH  LBAHA  GBH  GBD   AO  SBA  SBH  \\\n",
       "0  1.0  1.0   1.0   1.0  1.0    1.0   1.0    1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "\n",
       "   SBD     AFKC     HFKC       LBH       LBD      LBA  Referee     BbMxH  \\\n",
       "0  1.0  0.96227  0.96227  0.797885  0.797625  0.79751  0.62102  0.593979   \n",
       "\n",
       "      Bb1X2  BbAv>2.5      BbAH   BbAvAHH     BbAvH   BbMxAHA   BbMxAHH  \\\n",
       "0  0.593864  0.593662  0.593459  0.593459  0.593459  0.593402  0.593199   \n",
       "\n",
       "    BbAvAHA     BbMxD     BbAvD     BbMxA     BbAvA      BbOU  BbMx>2.5  \\\n",
       "0  0.593199  0.593199  0.593199  0.593199  0.593199  0.593199  0.593199   \n",
       "\n",
       "   BbMx<2.5  BbAv<2.5     BbAHh      WHCH      WHCA      WHCD   B365AHA  \\\n",
       "0  0.593199  0.593199  0.593199  0.414312  0.413937  0.413937  0.413388   \n",
       "\n",
       "    B365AHH    P<2.5      BWCD     BWCA     BWCH    P>2.5      PAHH     PAHA  \\\n",
       "0  0.413359  0.41203  0.411568  0.41151  0.41151  0.41151  0.411279  0.41099   \n",
       "\n",
       "   B365<2.5      IWCA      IWCD  B365>2.5      IWCH  B365C>2.5  B365CAHA  \\\n",
       "0  0.410008  0.409979  0.409776  0.409776  0.409661   0.409083  0.408939   \n",
       "\n",
       "   B365CAHH    PC<2.5   B365CH       AHh      AvgH     PCAHH     PCAHA  \\\n",
       "0  0.408939  0.408765  0.40865  0.408621  0.408621  0.408592  0.408563   \n",
       "\n",
       "    Avg>2.5    PC>2.5  B365C<2.5      VCCH    B365CA    B365CD    MaxAHA  \\\n",
       "0  0.408505  0.408419   0.408361  0.408303  0.408245  0.408245  0.408216   \n",
       "\n",
       "       AvgA   AvgCAHA    AvgAHA    AvgAHH    MaxAHH     AvgCA      AHCh  \\\n",
       "0  0.408101  0.408072  0.408072  0.408072  0.408014  0.407956  0.407956   \n",
       "\n",
       "    Max>2.5  Max<2.5  Avg<2.5      MaxH      VCCD      VCCA      MaxA  \\\n",
       "0  0.407956  0.40787  0.40787  0.407841  0.407841  0.407841  0.407841   \n",
       "\n",
       "       MaxD      AvgD     MaxCA     AvgCH      Time  MaxC>2.5  MaxCAHH  \\\n",
       "0  0.407841  0.407841  0.407812  0.407812  0.407725  0.407696  0.40761   \n",
       "\n",
       "      MaxCD     MaxCH  MaxC<2.5  AvgC>2.5  AvgC<2.5   MaxCAHA   AvgCAHH  \\\n",
       "0  0.407494  0.407494  0.407494  0.407494  0.407494  0.407494  0.407494   \n",
       "\n",
       "      AvgCD        HF        AF       PSH       PSA       PSD       WHD  \\\n",
       "0  0.407494  0.039146  0.039059  0.011527  0.010892  0.010747  0.009967   \n",
       "\n",
       "        WHA       WHH       BWD       BWA       BWH       VCH       VCD  \\\n",
       "0  0.009505  0.009447  0.007049  0.006616  0.006471  0.003785  0.003525   \n",
       "\n",
       "        VCA     B365A     B365D      IWD     B365H       IWH       IWA  \\\n",
       "0  0.003525  0.003496  0.003438  0.00338  0.003293  0.003091  0.003062   \n",
       "\n",
       "     PSCH    PSCD      PSCA       AR      HTR       HST        HC      HTHG  \\\n",
       "0  0.0026  0.0026  0.002485  0.00182  0.00182  0.001705  0.001473  0.001387   \n",
       "\n",
       "        AST        HY        HR        AY      Date        AC        AS  \\\n",
       "0  0.001329  0.001329  0.001184  0.001127  0.000982  0.000896  0.000896   \n",
       "\n",
       "         HS      HTAG      FTAG      FTHG  HomeTeam       FTR  season  league  \\\n",
       "0  0.000896  0.000838  0.000693  0.000549  0.000202  0.000029     0.0     0.0   \n",
       "\n",
       "   country  AwayTeam  Div  \n",
       "0      0.0       0.0  0.0  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_vals = pd.DataFrame((df.isna().sum()/df.shape[0]).sort_values( ascending=False)).T\n",
    "missing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOA</th>\n",
       "      <th>SBA</th>\n",
       "      <th>SYD</th>\n",
       "      <th>SJD</th>\n",
       "      <th>SBD</th>\n",
       "      <th>SOD</th>\n",
       "      <th>BSH</th>\n",
       "      <th>GBA</th>\n",
       "      <th>GBD</th>\n",
       "      <th>BSD</th>\n",
       "      <th>BSA</th>\n",
       "      <th>SYH</th>\n",
       "      <th>SJH</th>\n",
       "      <th>SBH</th>\n",
       "      <th>SOH</th>\n",
       "      <th>SJA</th>\n",
       "      <th>GBH</th>\n",
       "      <th>SYA</th>\n",
       "      <th>LBH</th>\n",
       "      <th>LBD</th>\n",
       "      <th>LBA</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSA</th>\n",
       "      <th>PSD</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>BWH</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365D</th>\n",
       "      <th>IWD</th>\n",
       "      <th>B365H</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797885</td>\n",
       "      <td>0.797625</td>\n",
       "      <td>0.79751</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SOA  SBA  SYD  SJD  SBD  SOD  BSH  GBA  GBD  BSD  BSA  SYH  SJH  SBH  SOH  \\\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "\n",
       "   SJA  GBH  SYA       LBH       LBD      LBA       PSH       PSA       PSD  \\\n",
       "0  1.0  1.0  1.0  0.797885  0.797625  0.79751  0.011527  0.010892  0.010747   \n",
       "\n",
       "        WHD       WHA       WHH       BWD       BWA       BWH       VCH  \\\n",
       "0  0.009967  0.009505  0.009447  0.007049  0.006616  0.006471  0.003785   \n",
       "\n",
       "        VCD       VCA     B365A     B365D      IWD     B365H       IWH  \\\n",
       "0  0.003525  0.003525  0.003496  0.003438  0.00338  0.003293  0.003091   \n",
       "\n",
       "        IWA  \n",
       "0  0.003062  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of completely missing odds: \n",
      " AvgH    37\n",
      "AvgD    37\n",
      "AvgA    37\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "bet_columns = [\"B365\", \"BS\", \"BW\", \"GB\", \"IW\", \"LB\", \"PS\", \"SO\", \"SB\", \"SJ\", \"SY\", \"VC\", \"WH\"]\n",
    "home_bet = [col+\"H\" for col in bet_columns]\n",
    "draw_bet = [col+\"D\" for col in bet_columns]\n",
    "away_bet = [col+\"A\" for col in bet_columns]\n",
    "\n",
    "#Check missing values\n",
    "bet_cols_missing_vals = (pd.DataFrame(df[home_bet + draw_bet + away_bet].isna().sum())/df.shape[0]).sort_values(by=0, ascending=False).T\n",
    "display(bet_cols_missing_vals)\n",
    "\n",
    "# We can see that IW, B365 have the least missing values, so we pick B365 odds and impute the\n",
    "# missing values based on the other odd columns\n",
    "df.loc[df[\"B365H\"].isna(), \"B365H\"] = df[home_bet].mean(axis=1)\n",
    "df.loc[df[\"B365D\"].isna(), \"B365D\"] = df[draw_bet].mean(axis=1)\n",
    "df.loc[df[\"B365A\"].isna(), \"B365A\"] = df[away_bet].mean(axis=1)\n",
    "\n",
    "# Rename columns\n",
    "df[\"AvgH\"] = df[\"B365H\"].copy()\n",
    "df[\"AvgD\"] = df[\"B365D\"].copy()\n",
    "df[\"AvgA\"] = df[\"B365A\"].copy()\n",
    "\n",
    "\n",
    "# Drop the extra odds columns data and matches where we have completely missing odds\n",
    "print(\"Number of completely missing odds: \\n\", df.loc[:,[\"AvgH\", \"AvgD\", \"AvgA\"]].isna().sum())\n",
    "\n",
    "#Drop unnecessary columns\n",
    "df.drop(home_bet + draw_bet + away_bet, axis = 1, inplace=True)\n",
    "df.drop([\"PSCH\", \"PSCD\", \"PSCA\"], axis = 1, inplace=True)\n",
    "\n",
    "def dropnas(df):\n",
    "    # We drop the values where there are missing non-imputable values in main columns\n",
    "    df = df.loc[~df[\"FTHG\"].isna() & ~df[\"FTAG\"].isna() & (df[\"FTAG\"] > -1) & (df[\"FTHG\"] > -1)].copy()\n",
    "    df = df.loc[~df[\"HTHG\"].isna() & ~df[\"HTAG\"].isna()].copy()\n",
    "    df = df.loc[~df[\"HomeTeam\"].isna() & ~df[\"AwayTeam\"].isna()].copy()\n",
    "    df = df.loc[~df[\"AvgH\"].isna() & ~df[\"AvgD\"].isna() & ~df[\"AvgA\"].isna(), :]\n",
    "    df = df.loc[~df[\"Div\"].isna() & ~df[\"Date\"].isna()].copy()\n",
    "    df = df.loc[~df[\"FTR\"].isna() & ~df[\"HTR\"].isna()].copy()\n",
    "    \t\n",
    "    return df\n",
    "\n",
    "def process_dates(df):\n",
    "    df[\"Date\"] = df[\"Date\"].apply(\n",
    "        lambda date: datetime.strptime(date, \"%d/%m/%y\") if len(date)==8 else datetime.strptime(date, \"%d/%m/%Y\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def fill_goals(df):\n",
    "    df[\"HTR\"] = calculate_win(df[\"HTHG\"], df[\"HTAG\"])\n",
    "    df[\"FTR_test\"] = calculate_win(df[\"FTHG\"], df[\"FTAG\"])\n",
    "    return df\n",
    "\n",
    "def calculate_win(home_goals, away_goals):\n",
    "    results = []\n",
    "    for home, away in zip(home_goals, away_goals):\n",
    "        if home < away:\n",
    "            results.append(\"A\")\n",
    "        elif home > away:\n",
    "            results.append(\"H\")\n",
    "        else:\n",
    "            results.append(\"D\")\n",
    "    return results\n",
    "\n",
    "def drop_goal_outliers(df):\n",
    "    df = df.loc[(df[\"FTHG\"] + df[\"FTAG\"]) < 20, :].copy()\n",
    "    return df\n",
    "\n",
    "df = dropnas(df)\n",
    "df = process_dates(df)\n",
    "df = fill_goals(df)\n",
    "df = drop_goal_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHW</th>\n",
       "      <th>HBP</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>B365AH</th>\n",
       "      <th>HO</th>\n",
       "      <th>AHW</th>\n",
       "      <th>GBAH</th>\n",
       "      <th>GBAHA</th>\n",
       "      <th>GBAHH</th>\n",
       "      <th>GB&lt;2.5</th>\n",
       "      <th>AO</th>\n",
       "      <th>GB&gt;2.5</th>\n",
       "      <th>ABP</th>\n",
       "      <th>LBAHH</th>\n",
       "      <th>LBAHA</th>\n",
       "      <th>LBAH</th>\n",
       "      <th>LB</th>\n",
       "      <th>LB.1</th>\n",
       "      <th>LB.2</th>\n",
       "      <th>HT</th>\n",
       "      <th>AT</th>\n",
       "      <th>AFKC</th>\n",
       "      <th>HFKC</th>\n",
       "      <th>Referee</th>\n",
       "      <th>BbMxH</th>\n",
       "      <th>Bb1X2</th>\n",
       "      <th>BbAv&gt;2.5</th>\n",
       "      <th>BbAvAHH</th>\n",
       "      <th>BbAvH</th>\n",
       "      <th>BbAH</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbMxD</th>\n",
       "      <th>BbOU</th>\n",
       "      <th>BbMxA</th>\n",
       "      <th>BbAvAHA</th>\n",
       "      <th>BbAvA</th>\n",
       "      <th>BbAvD</th>\n",
       "      <th>BbAv&lt;2.5</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>BbMx&gt;2.5</th>\n",
       "      <th>BbMxAHH</th>\n",
       "      <th>BbMx&lt;2.5</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>P&lt;2.5</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>P&gt;2.5</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>AHh</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>Avg&gt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>Time</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>Max&gt;2.5</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>Max&lt;2.5</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>Avg&lt;2.5</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>AR</th>\n",
       "      <th>HST</th>\n",
       "      <th>HC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AST</th>\n",
       "      <th>HR</th>\n",
       "      <th>AY</th>\n",
       "      <th>AC</th>\n",
       "      <th>AS</th>\n",
       "      <th>HS</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>season</th>\n",
       "      <th>league</th>\n",
       "      <th>country</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>FTR_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.59402</td>\n",
       "      <td>0.593816</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593438</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.413433</td>\n",
       "      <td>0.413112</td>\n",
       "      <td>0.413112</td>\n",
       "      <td>0.412239</td>\n",
       "      <td>0.41221</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.410609</td>\n",
       "      <td>0.410609</td>\n",
       "      <td>0.410609</td>\n",
       "      <td>0.410405</td>\n",
       "      <td>0.410172</td>\n",
       "      <td>0.409881</td>\n",
       "      <td>0.409095</td>\n",
       "      <td>0.40892</td>\n",
       "      <td>0.408891</td>\n",
       "      <td>0.408775</td>\n",
       "      <td>0.408687</td>\n",
       "      <td>0.408251</td>\n",
       "      <td>0.408047</td>\n",
       "      <td>0.408047</td>\n",
       "      <td>0.407901</td>\n",
       "      <td>0.407814</td>\n",
       "      <td>0.407727</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0.407552</td>\n",
       "      <td>0.407523</td>\n",
       "      <td>0.407523</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.407406</td>\n",
       "      <td>0.407406</td>\n",
       "      <td>0.407348</td>\n",
       "      <td>0.407348</td>\n",
       "      <td>0.407232</td>\n",
       "      <td>0.407232</td>\n",
       "      <td>0.407086</td>\n",
       "      <td>0.407057</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.40697</td>\n",
       "      <td>0.40697</td>\n",
       "      <td>0.406941</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.406882</td>\n",
       "      <td>0.406853</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HHW  HBP  Attendance  B365AH   HO  AHW  GBAH  GBAHA  GBAHH  GB<2.5   AO  \\\n",
       "0  1.0  1.0         1.0     1.0  1.0  1.0   1.0    1.0    1.0     1.0  1.0   \n",
       "\n",
       "   GB>2.5  ABP  LBAHH  LBAHA  LBAH   LB  LB.1  LB.2   HT   AT      AFKC  \\\n",
       "0     1.0  1.0    1.0    1.0   1.0  1.0   1.0   1.0  1.0  1.0  0.962415   \n",
       "\n",
       "       HFKC   Referee    BbMxH     Bb1X2  BbAv>2.5   BbAvAHH     BbAvH  \\\n",
       "0  0.962415  0.620513  0.59402  0.593816    0.5937  0.593496  0.593496   \n",
       "\n",
       "       BbAH   BbMxAHA     BbMxD      BbOU     BbMxA   BbAvAHA     BbAvA  \\\n",
       "0  0.593496  0.593438  0.593234  0.593234  0.593234  0.593234  0.593234   \n",
       "\n",
       "      BbAvD  BbAv<2.5     BbAHh  BbMx>2.5   BbMxAHH  BbMx<2.5      WHCH  \\\n",
       "0  0.593234  0.593234  0.593234  0.593234  0.593234  0.593234  0.413433   \n",
       "\n",
       "       WHCA      WHCD   B365AHA  B365AHH   P<2.5      BWCD      BWCH  \\\n",
       "0  0.413112  0.413112  0.412239  0.41221  0.4109  0.410609  0.410609   \n",
       "\n",
       "       BWCA     P>2.5      PAHH      PAHA      IWCA  B365<2.5      IWCD  \\\n",
       "0  0.410609  0.410405  0.410172  0.409881  0.409095   0.40892  0.408891   \n",
       "\n",
       "       IWCH  B365>2.5  B365C>2.5  B365CAHH  B365CAHA    PC<2.5    B365CH  \\\n",
       "0  0.408775  0.408687   0.408251  0.408047  0.408047  0.407901  0.407814   \n",
       "\n",
       "      PCAHH     PCAHA    PC>2.5  B365C<2.5       AHh      VCCH    B365CA  \\\n",
       "0  0.407727  0.407697  0.407552   0.407523  0.407523  0.407494  0.407406   \n",
       "\n",
       "     B365CD   AvgCAHA   Avg>2.5      AHCh     AvgCA     MaxCA    MaxAHA  \\\n",
       "0  0.407406  0.407348  0.407348  0.407232  0.407232  0.407086  0.407057   \n",
       "\n",
       "      AvgCH      VCCA      Time      VCCD  MaxC>2.5   AvgAHA    AvgAHH  \\\n",
       "0  0.407028  0.407028  0.407028  0.407028   0.40697  0.40697  0.406941   \n",
       "\n",
       "     MaxAHH   MaxCAHH   Max>2.5     AvgCD   MaxCAHA  AvgC>2.5  MaxC<2.5  \\\n",
       "0  0.406911  0.406882  0.406853  0.406766  0.406766  0.406766  0.406766   \n",
       "\n",
       "    AvgCAHH  AvgC<2.5   Max<2.5     MaxCD      MaxH     MaxCH      MaxA  \\\n",
       "0  0.406766  0.406766  0.406766  0.406766  0.406766  0.406766  0.406766   \n",
       "\n",
       "       MaxD   Avg<2.5        HF        AF        AR       HST        HC  \\\n",
       "0  0.406766  0.406766  0.038138  0.038051  0.000961  0.000844  0.000553   \n",
       "\n",
       "         HY       AST        HR        AY        AC        AS        HS  Div  \\\n",
       "0  0.000437  0.000408  0.000262  0.000262  0.000029  0.000029  0.000029  0.0   \n",
       "\n",
       "   Date  AvgA  AvgD  AvgH  season  league  country  HTR  HTAG  HTHG  FTR  \\\n",
       "0   0.0   0.0   0.0   0.0     0.0     0.0      0.0  0.0   0.0   0.0  0.0   \n",
       "\n",
       "   FTAG  FTHG  AwayTeam  HomeTeam  FTR_test  \n",
       "0   0.0   0.0       0.0       0.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_vals = pd.DataFrame((df.isna().sum()/df.shape[0]).sort_values( ascending=False)).T\n",
    "display(missing_vals)\n",
    "# We can see there is a group of columns that have a lot of missing values and \n",
    "# are irrelevant to our analysis, so we also drop them\n",
    "to_drop = ['GBAHA', 'HBP', 'HO', 'AHW', 'B365AH', 'HHW', 'Attendance', 'GBAH',\n",
    "       'GBAHH', 'GB>2.5', 'AO', 'GB<2.5', 'ABP', 'LB', 'AT', 'HT',\n",
    "       'LBAHH', 'LB.1', 'LB.2', 'LBAH', 'LBAHA', 'AFKC', 'HFKC', 'Bb1X2',\n",
    "       'BbAv>2.5', 'BbAH', 'BbAvH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA',\n",
    "       'BbMxAHH', 'BbAHh', 'BbMx<2.5', 'BbAv<2.5', 'BbMxA', 'BbMxD',\n",
    "       'BbAvD', 'BbMxH', 'BbAvA', 'BbOU', 'BbMx>2.5', 'Referee', 'WHCH',\n",
    "       'WHCD', 'WHCA', 'B365AHA', 'B365AHH', 'P<2.5', 'BWCD', 'BWCH',\n",
    "       'BWCA', 'P>2.5', 'PAHH', 'PAHA', 'IWCA', 'B365<2.5', 'IWCD',\n",
    "       'IWCH', 'B365>2.5', 'B365C>2.5', 'B365CAHH', 'B365CAHA', 'PC<2.5',\n",
    "       'B365CH', 'PCAHH', 'PCAHA', 'PC>2.5', 'B365C<2.5', 'AHh', 'VCCH',\n",
    "       'B365CD', 'B365CA', 'AvgCAHA', 'Avg>2.5', 'AvgCA', 'AHCh', 'MaxCA',\n",
    "       'MaxAHA', 'Time', 'AvgCH', 'VCCD', 'VCCA', 'AvgAHA', 'MaxC>2.5',\n",
    "       'AvgAHH', 'MaxAHH', 'MaxCAHH', 'Max>2.5', 'MaxC<2.5', 'AvgC>2.5',\n",
    "       'AvgC<2.5', 'AvgCD', 'Max<2.5', 'MaxD', 'MaxCD', 'AvgCAHH',\n",
    "       'MaxCH', 'MaxH', 'MaxCAHA', 'MaxA', 'Avg<2.5']\n",
    "\n",
    "df = df.drop(to_drop, axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong result in matches:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>AR</th>\n",
       "      <th>HST</th>\n",
       "      <th>HC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AST</th>\n",
       "      <th>HR</th>\n",
       "      <th>AY</th>\n",
       "      <th>AS</th>\n",
       "      <th>AC</th>\n",
       "      <th>HS</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>season</th>\n",
       "      <th>league</th>\n",
       "      <th>country</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>FTR_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HF        AF        AR       HST        HC        HY       AST  \\\n",
       "0  0.038138  0.038051  0.000961  0.000844  0.000553  0.000437  0.000408   \n",
       "\n",
       "         HR        AY        AS        AC        HS  AvgA  AvgD  AvgH  Div  \\\n",
       "0  0.000262  0.000262  0.000029  0.000029  0.000029   0.0   0.0   0.0  0.0   \n",
       "\n",
       "   Date  season  league  country  HTR  HTAG  HTHG  FTR  FTAG  FTHG  AwayTeam  \\\n",
       "0   0.0     0.0     0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0       0.0   \n",
       "\n",
       "   HomeTeam  FTR_test  \n",
       "0       0.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Wrong result in matches: \", (~(df[\"FTR\"] == df[\"FTR_test\"])).sum())\n",
    "# We fix the wrong results\n",
    "df[\"FTR\"] = df[\"FTR_test\"].copy()\n",
    "\n",
    "# Check missing values again\n",
    "missing_vals = pd.DataFrame((df.isna().sum()/df.shape[0]).sort_values( ascending=False)).T\n",
    "display(missing_vals)\n",
    "\n",
    "# For now we will exclude the fouls columns due to missing values, \n",
    "#and for the rest of the values, we impute them using mean\n",
    "\n",
    "df_cleaned = df.drop([\"HF\", \"AF\", \"FTR_test\"], axis=1).copy()\n",
    "missing_vals = pd.DataFrame((df_cleaned.isna().sum()/df_cleaned.shape[0]).sort_values( ascending=False)).T\n",
    "\n",
    "# Which columns need to be imputed\n",
    "to_impute = (missing_vals.T)[(missing_vals.T)[0] > 0].index.tolist()\n",
    "to_impute\n",
    "\n",
    "# a tiny bit data leakage, to be fixed\n",
    "def mean_imputer(df, features):\n",
    "    for col in features:\n",
    "        mean = df.loc[~df[col].isna(), col].mean()\n",
    "        df.loc[df[col].isna(), col] = mean \n",
    "    return df\n",
    "df_cleaned = mean_imputer(df_cleaned, to_impute).reset_index(drop=True)\n",
    "\n",
    "# We identify where we need to swap order of matches in order to generate unique match key\n",
    "df_cleaned[\"swap_needed\"] = df_cleaned[\"HomeTeam\"] > df_cleaned[\"AwayTeam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>AS</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AR</th>\n",
       "      <th>HR</th>\n",
       "      <th>AY</th>\n",
       "      <th>HY</th>\n",
       "      <th>AC</th>\n",
       "      <th>HC</th>\n",
       "      <th>AST</th>\n",
       "      <th>HST</th>\n",
       "      <th>HS</th>\n",
       "      <th>Date</th>\n",
       "      <th>season</th>\n",
       "      <th>league</th>\n",
       "      <th>country</th>\n",
       "      <th>HTR</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>swap_needed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div   AS  AvgA  AvgD  AvgH   AR   HR   AY   HY   AC   HC  AST  HST   HS  \\\n",
       "0  0.0  0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   Date  season  league  country  HTR  HTAG  HTHG  FTR  FTAG  FTHG  AwayTeam  \\\n",
       "0   0.0     0.0     0.0      0.0  0.0   0.0   0.0  0.0   0.0   0.0       0.0   \n",
       "\n",
       "   HomeTeam  swap_needed  \n",
       "0       0.0          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final check for missing values\n",
    "missing_vals = pd.DataFrame((df_cleaned.isna().sum()/df_cleaned.shape[0]).sort_values( ascending=False)).T\n",
    "display(missing_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Renaming and reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity and reorder them\n",
    "new_names = {\n",
    "    \"country\": \"Country\",\n",
    "    \"league\": \"League\",\n",
    "    \"Div\": \"Division\",\n",
    "    \"season\": \"Season\",\n",
    "    \"Date\": \"Date\",\n",
    "    \"HomeTeam\": \"HomeTeam\",\n",
    "    \"AwayTeam\": \"AwayTeam\",\n",
    "    \"FTHG\": \"HomeGoals\",\n",
    "    \"FTAG\": \"AwayGoals\",\n",
    "    \"FTR\": \"Result\",\n",
    "    \"AvgH\": \"AvgHomeOdds\",\n",
    "    \"AvgD\": \"AvgDrawOdds\",\n",
    "    \"AvgA\": \"AvgAwayOdds\",\n",
    "    \"HTHG\": \"HomeGoalsHalf\",\n",
    "    \"HTAG\": \"AwayGoalsHalf\",\n",
    "    \"HTR\": \"HalfResult\",\n",
    "    \"HS\": \"HomeShots\",\n",
    "    \"AS\": \"AwayShots\",\n",
    "    \"HST\": \"HomeShotsTarget\",\n",
    "    \"AST\": \"AwayShotsTarget\",\n",
    "    \"HC\": \"HomeCorners\",\n",
    "    \"AC\": \"AwayCorners\",\n",
    "    \"HY\": \"HomeYellowCards\",\n",
    "    \"AY\": \"AwayYellowCards\",\n",
    "    \"HR\": \"HomeRedCards\",\n",
    "    \"AR\": \"AwayRedCards\",\n",
    "    \"swap_needed\": \"swap_needed\"\n",
    "    }\n",
    "df_cleaned = df_cleaned.rename(columns=new_names)\n",
    "df_cleaned.columns.values\n",
    "df_cleaned = df_cleaned.loc[:, new_names.values()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into train and test dataframe, and test is season 21, train is rest\n",
    "X_train = df_cleaned.loc[(df_cleaned[\"Season\"] != 21), :].drop([\"Result\"], axis=1)\n",
    "y_train = df_cleaned.loc[(df_cleaned[\"Season\"] != 21) , \"Result\"]\n",
    "X_test = df_cleaned.loc[(df_cleaned[\"Season\"] == 21), :].drop([\"Result\"], axis=1)\n",
    "y_test = df_cleaned.loc[(df_cleaned[\"Season\"] == 21), \"Result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matchup specific statistics calculation per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>SeasonKey</th>\n",
       "      <th>MatchKey</th>\n",
       "      <th>HomeGoals</th>\n",
       "      <th>AwayGoals</th>\n",
       "      <th>HomeShots</th>\n",
       "      <th>AwayShots</th>\n",
       "      <th>HomeCorners</th>\n",
       "      <th>AwayCorners</th>\n",
       "      <th>HomeWins</th>\n",
       "      <th>Draws</th>\n",
       "      <th>AwayWins</th>\n",
       "      <th>HomeGoals_cum</th>\n",
       "      <th>AwayGoals_cum</th>\n",
       "      <th>HomeShots_cum</th>\n",
       "      <th>AwayShots_cum</th>\n",
       "      <th>HomeWins_cum</th>\n",
       "      <th>Draws_cum</th>\n",
       "      <th>AwayWins_cum</th>\n",
       "      <th>HomeCorners_cum</th>\n",
       "      <th>AwayCorners_cum</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>17</td>\n",
       "      <td>AnderlechtAntwerp</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>B1</td>\n",
       "      <td>18</td>\n",
       "      <td>AnderlechtAntwerp</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>B1</td>\n",
       "      <td>19</td>\n",
       "      <td>AnderlechtAntwerp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>B1</td>\n",
       "      <td>20</td>\n",
       "      <td>AnderlechtAntwerp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Division  SeasonKey           MatchKey  HomeGoals  AwayGoals  HomeShots  \\\n",
       "0           B1         17  AnderlechtAntwerp        2.0        1.0       15.0   \n",
       "6527        B1         18  AnderlechtAntwerp        2.0        1.0       12.0   \n",
       "8033        B1         19  AnderlechtAntwerp        1.0        2.0       18.0   \n",
       "11067       B1         20  AnderlechtAntwerp        5.0        1.0       28.0   \n",
       "\n",
       "       AwayShots  HomeCorners  AwayCorners  HomeWins  Draws  AwayWins  \\\n",
       "0           15.0          5.0         14.0         1      1         0   \n",
       "6527        16.0         11.0         11.0         1      1         0   \n",
       "8033        24.0         11.0         13.0         0      1         1   \n",
       "11067       24.0         11.0          7.0         2      0         0   \n",
       "\n",
       "       HomeGoals_cum  AwayGoals_cum  HomeShots_cum  AwayShots_cum  \\\n",
       "0                2.0            1.0           15.0           15.0   \n",
       "6527             4.0            2.0           27.0           31.0   \n",
       "8033             5.0            4.0           45.0           55.0   \n",
       "11067           10.0            5.0           73.0           79.0   \n",
       "\n",
       "       HomeWins_cum  Draws_cum  AwayWins_cum  HomeCorners_cum  \\\n",
       "0                 1          1             0              5.0   \n",
       "6527              2          2             0             16.0   \n",
       "8033              2          3             1             27.0   \n",
       "11067             4          3             1             38.0   \n",
       "\n",
       "       AwayCorners_cum  matches  \n",
       "0                 14.0        2  \n",
       "6527              25.0        4  \n",
       "8033              38.0        6  \n",
       "11067             45.0        8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we will try to get specific matchup statistics\n",
    "hf = ['HomeTeam', 'HomeGoals', 'AvgHomeOdds', 'HomeGoalsHalf', 'HomeShots',  'HomeShotsTarget', 'HomeCorners',  'HomeYellowCards', 'HomeRedCards']\n",
    "af = ['AwayTeam', 'AwayGoals', 'AvgAwayOdds', 'AwayGoalsHalf', 'AwayShots',  'AwayShotsTarget', 'AwayCorners',  'AwayYellowCards', 'AwayRedCards']\n",
    "\n",
    "# We identify matches where we have to swap their order, so that we can calculate matchup specific statistics\n",
    "\n",
    "def swap_result(x):\n",
    "    if x == \"H\":\n",
    "        return \"A\"\n",
    "    if x == \"A\":\n",
    "        return \"H\"\n",
    "    return \"D\"\n",
    "def get_matchup_statistics(df,home_features,away_features, target, stats):\n",
    "    grouped_df = df.copy()    \n",
    "    mask = grouped_df[\"swap_needed\"]    \n",
    "    for hf, af in zip(home_features, away_features):\n",
    "        # Swap the features where swap_needed is True\n",
    "        temp = grouped_df.loc[mask, hf].copy()\n",
    "        grouped_df.loc[mask, hf] = grouped_df.loc[mask, af]\n",
    "        grouped_df.loc[mask, af] = temp\n",
    "    \n",
    "    # Also correct the result according to the swapped statistics\n",
    "    grouped_df.loc[mask,\"HalfResult\"] = grouped_df.loc[mask,\"HalfResult\"].apply(lambda x: swap_result(x))\n",
    "    \n",
    "    # Add result and swap it correctly\n",
    "    grouped_df[\"Result\"] = target\n",
    "    grouped_df.loc[mask, \"Result\"] = grouped_df.loc[mask, \"Result\"].apply(lambda x: swap_result(x))\n",
    "    \n",
    "    # Create unique identifier for specific matchup\n",
    "    grouped_df[\"MatchKey\"] = grouped_df[\"HomeTeam\"] + grouped_df[\"AwayTeam\"]\n",
    "\n",
    "    # Group by Divison, Season and matchkey to get per-season statistics for specific unique  matchups\n",
    "    group = grouped_df.groupby([\"Division\", \"Season\", \"MatchKey\"])\n",
    "\n",
    "    #Get the aggregated statistics that were passed to function\n",
    "    statistics = group[stats].agg([\"sum\",\"count\"]).reset_index()\n",
    "    \n",
    "    #Now reset the two level column index to one level with the specific aggregates only\n",
    "    selected_columns = [\n",
    "    ('Division', ''),\n",
    "    ('Season', ''),\n",
    "    ('MatchKey', ''),\n",
    "    ('HomeGoals', 'sum'),\n",
    "    ('AwayGoals', 'sum'),\n",
    "    ('HomeShots', 'sum'),\n",
    "    ('AwayShots', 'sum'),\n",
    "    ('HomeCorners', 'sum'),\n",
    "    ('AwayCorners', 'sum'),\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Reducing to a single level index\n",
    "    statistics = statistics[selected_columns]\n",
    "    statistics.columns = [col[0] if type(col) is tuple else col for col in statistics.columns.values]\n",
    "\n",
    "    count_H = group['Result'].apply(lambda x: (x == 'H').sum()).reset_index().rename(columns={\"Result\": \"HomeWins\"})\n",
    "    count_D = group['Result'].apply(lambda x: (x == 'D').sum()).reset_index().rename(columns={\"Result\": \"Draws\"})\n",
    "    count_A = group['Result'].apply(lambda x: (x == 'A').sum()).reset_index().rename(columns={\"Result\": \"AwayWins\"})\n",
    "\n",
    "    # Merge with home/draw/away result statistics\n",
    "    statistics = pd.merge(statistics, count_H, on = [\"Division\", \"Season\", \"MatchKey\"], how='left')\n",
    "    statistics = pd.merge(statistics, count_D, on = [\"Division\", \"Season\", \"MatchKey\"], how='left')\n",
    "    statistics = pd.merge(statistics, count_A, on = [\"Division\", \"Season\", \"MatchKey\"], how='left')\n",
    "\n",
    "    statistics = statistics.sort_values(by='Season')\n",
    "    cumulative_stats = [\"HomeGoals\", \"AwayGoals\", \"HomeShots\", \"AwayShots\", \"HomeWins\", \"Draws\", \"AwayWins\", \"HomeCorners\", \"AwayCorners\"]\n",
    "    \n",
    "    for col in cumulative_stats:\n",
    "        statistics[col + \"_cum\"] = statistics.groupby(['Division', 'MatchKey'])[col].cumsum()\n",
    "        \n",
    "    statistics[\"matches\"] = statistics[\"HomeWins_cum\"] + statistics[\"Draws_cum\"] + statistics[\"AwayWins_cum\"]\n",
    "        \n",
    "    return statistics\n",
    "stats = [\"HomeGoals\", \"AwayGoals\", \"HomeShots\", \"AwayShots\",\"HomeCorners\", \"AwayCorners\", \"Result\"]\n",
    "statistics = get_matchup_statistics(X_train, hf, af, y_train, stats)\n",
    "statistics = statistics.rename(columns={\"Season\": \"SeasonKey\"}).reset_index(drop=True)\n",
    "display(statistics.loc[statistics.MatchKey==\"AnderlechtAntwerp\", :].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging matchup specific statistics and matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_cleaned.loc[(df_cleaned[\"Season\"] != 21), :].drop([\"Result\"], axis=1)\n",
    "y_train = df_cleaned.loc[(df_cleaned[\"Season\"] != 21) , \"Result\"]\n",
    "X_test = df_cleaned.loc[(df_cleaned[\"Season\"] == 21), :].drop([\"Result\"], axis=1)\n",
    "y_test = df_cleaned.loc[(df_cleaned[\"Season\"] == 21), \"Result\"]\n",
    "\n",
    "# Create keys for merging with statistics\n",
    "def generate_match_keys(row):\n",
    "    match_key = row[\"AwayTeam\"] + row[\"HomeTeam\"] if row[\"swap_needed\"] else row[\"HomeTeam\"] + row[\"AwayTeam\"] \n",
    "    return match_key\n",
    "\n",
    "X_train[\"MatchKey\"] = X_train.apply(lambda x: generate_match_keys(x), axis=1) \n",
    "X_test[\"MatchKey\"] = X_test.apply(lambda x: generate_match_keys(x), axis=1)\n",
    "\n",
    "X_train[\"SeasonKey\"] = X_train[\"Season\"] - 1\n",
    "X_test[\"SeasonKey\"] = X_test[\"Season\"] - 1\n",
    "\n",
    "\n",
    "merging_keys = [\"Division\", \"SeasonKey\", \"MatchKey\"]\n",
    "home_stats = ['HomeGoals_cum',\n",
    "              'HomeShots_cum',\n",
    "              'HomeWins_cum',\n",
    "              \"HomeCorners_cum\"\n",
    "             ]\n",
    "away_stats = ['AwayGoals_cum',\n",
    "              'AwayShots_cum',\n",
    "              'AwayWins_cum',\n",
    "              'AwayCorners_cum'\n",
    "             ]\n",
    "other_stats = [\"Draws_cum\", \"matches\"]\n",
    "all_stats = home_stats + away_stats + other_stats\n",
    "\n",
    "# Define a function to swap statistics in case the teams\n",
    "# have different order than the MatchKey\n",
    "def swap_feature_values(data, home_stats, away_stats):\n",
    "    mask = data[\"swap_needed\"]\n",
    "    for hst, ast in zip(home_stats, away_stats):\n",
    "        # Swap the features where swap_needed is True\n",
    "        temp = data.loc[mask, hst].copy()\n",
    "        data.loc[mask, hst] = data.loc[mask, ast]\n",
    "        data.loc[mask, ast] = temp\n",
    "    return data\n",
    "\n",
    "X_train = pd.merge(X_train, statistics[merging_keys + all_stats], on=merging_keys, how='left')\n",
    "X_test = pd.merge(X_test, statistics[merging_keys + all_stats], on=merging_keys, how='left')\n",
    "\n",
    "X_train = swap_feature_values(X_train, home_stats, away_stats).reset_index(drop=True)\n",
    "X_test = swap_feature_values(X_test, home_stats, away_stats).reset_index(drop=True)\n",
    "\n",
    "# We have to drop these stats since they cannot be used for prediction of matches\n",
    "#(they are known only after the match occured)\n",
    "to_drop = ['HomeGoals', 'AwayGoals','HomeGoalsHalf', 'AwayGoalsHalf', 'HalfResult',\n",
    "       'HomeShots', 'AwayShots', 'HomeShotsTarget', 'AwayShotsTarget',\n",
    "       'HomeCorners', 'AwayCorners', 'HomeYellowCards', 'AwayYellowCards',\n",
    "       'HomeRedCards', 'AwayRedCards']\n",
    "\n",
    "X_train = X_train.drop(to_drop, axis=1).reset_index(drop=True)\n",
    "X_test = X_test.drop(to_drop, axis=1).reset_index(drop=True)\n",
    "X_train[\"HWR\"] = X_train[\"HomeWins_cum\"]/X_train[\"matches\"] \n",
    "X_test[\"HWR\"] = X_test[\"HomeWins_cum\"]/X_test[\"matches\"]\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = X_train.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(train_data):\n",
    "    folds = []\n",
    "    for x in range(len(train_data.Season.unique())-1):\n",
    "        folds.append({\"train\": seasons[:(x+1)],\n",
    "                      \"val\": [seasons[x]+1]})\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_param_combinations(grid):\n",
    "    # Extract the keys and the corresponding lists of possible values\n",
    "    keys, values = zip(*grid.items())\n",
    "    \n",
    "    # Use itertools.product to get all combinations of parameter values\n",
    "    all_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    return all_combinations\n",
    "\n",
    "def cross_validate(model, data_x, data_y, grid):\n",
    "    folds = get_folds(data_x)\n",
    "    parameters_grid = {}\n",
    "    param_sets = get_param_combinations(grid)\n",
    "    scores = []\n",
    "    total_sets = len(param_sets)\n",
    "    cou = 0\n",
    "    for hyperp in param_sets:\n",
    "        temp = []\n",
    "        for i in folds:\n",
    "            X_train = data_x.loc[data_x.Season.isin(i[\"train\"]), :]\n",
    "            X_val = data_x.loc[data_x.Season.isin(i[\"val\"]), :]\n",
    "            y_train = data_y[X_train.index.values] \n",
    "            y_val = data_y[X_val.index.values]\n",
    "            \n",
    "            model.set_params(**hyperp)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_val)\n",
    "            temp.append(f1_score(y_val, y_pred, average=\"macro\"))\n",
    "\n",
    "        mean_score = np.mean(np.array(temp))\n",
    "        cou = cou + 1\n",
    "        print(\"Progress: \", str(cou/total_sets), \"Score: \", mean_score)\n",
    "        scores.append({\"hyperparameters\": hyperp,\n",
    "                      \"mean_score\": mean_score})\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [7, 9, 11, 13],\n",
    "    'min_samples_split': [3, 6, 9],\n",
    "    'n_jobs': [4]\n",
    "}\n",
    "#model = RandomForestClassifier()\n",
    "#features = [\"AvgHomeOdds\", \"AvgDrawOdds\", \"AvgAwayOdds\"]\n",
    "#result = cross_validate(model, X_train[features+[\"Season\"]], y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3966671943881847},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3905699319561627},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3945267527962247},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3986917185581216},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3985645370264521},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39849699793968724},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40182761677495643},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4075510094002788},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40577471553400885},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40066968425068983},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.407389792770447},\n",
       " {'hyperparameters': {'n_estimators': 100,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40514118414769046},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39637282769495186},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.3939384745225409},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39247381766148415},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39819577776816195},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4011982692272115},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4020446506596977},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4018331467908986},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40307358889996786},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40347560409890426},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40131869350098254},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4039716857603344},\n",
       " {'hyperparameters': {'n_estimators': 200,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40606284200722836},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39385867935898916},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39361482052641256},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 7,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.39416838177526575},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40177846536576095},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40021999153125026},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 9,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4012418383309541},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4017697065600249},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40383410404612935},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 11,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40408803764432283},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 3,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4022897844434678},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 6,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.4067166501413407},\n",
       " {'hyperparameters': {'n_estimators': 300,\n",
       "   'max_depth': 13,\n",
       "   'min_samples_split': 9,\n",
       "   'n_jobs': 4},\n",
       "  'mean_score': 0.40500979709589285}]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for each division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_pipeline(X_train, X_test, y_train, y_test, na_features, non_na_features):\n",
    "    train_na = X_train.isna().any(axis=1)\n",
    "    test_na = X_test.isna().any(axis=1)\n",
    "    \n",
    "    train_ind = X_train[train_na].index.values\n",
    "    test_ind = X_test[test_na].index.values\n",
    "\n",
    "    train_ind_nonna = X_train[~train_na].index.values\n",
    "    test_ind_nonna = X_test[~test_na].index.values\n",
    "    \n",
    "    \n",
    "    # Splitting the datasets\n",
    "    X_train_na, y_train_na = X_train[train_na], y_train[train_ind]\n",
    "    X_train_no_na, y_train_no_na = X_train[~train_na], y_train[train_ind_nonna]\n",
    "    \n",
    "    X_test_na, y_test_na = X_test[test_na], y_test[test_ind]\n",
    "    X_test_no_na, y_test_no_na = X_test[~test_na], y_test[test_ind_nonna]\n",
    "    \n",
    "    # Initialize models (you can choose any model)\n",
    "    model_na = xgb.XGBClassifier(nthread=6,max_depth=4,n_estimators=100)\n",
    "    model_no_na = xgb.XGBClassifier(nthread=6,max_depth=4,n_estimators=100)\n",
    "    \n",
    "    # Train models\n",
    "    model_na.fit(X_train_na[na_features]\n",
    "                 , y_train_na)\n",
    "    model_no_na.fit(X_train_no_na[non_na_features],\n",
    "                    y_train_no_na)\n",
    "    \n",
    "    # Evaluate models (optional)\n",
    "    preds_na = model_na.predict(X_test_na[na_features])\n",
    "    preds_no_na = model_no_na.predict(X_test_no_na[non_na_features])\n",
    "    \n",
    "    f1_score_na = f1_score(y_test_na, preds_na, average=\"macro\")\n",
    "    f1_score_no_na = f1_score(y_test_no_na, preds_no_na, average=\"macro\")\n",
    "    \n",
    "    return {\n",
    "    #\"model_na\": model_na,\n",
    "    #\"model_no_na\": model_no_na,    \n",
    "    \"f1_test_na\": f1_score_na,\n",
    "    \"f1_test_no_na\": f1_score_no_na}\n",
    "\n",
    "\n",
    "#na_features = [\"AvgHomeOdds\", \"AvgDrawOdds\", \"AvgAwayOdds\"]\n",
    "#non_na_features = [\"AvgHomeOdds\", \"AvgDrawOdds\", \"AvgAwayOdds\"] +  #+ all_stats\n",
    "#scores = predictive_pipeline(X_train, X_test, y_train, y_test, na_features, non_na_features)\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = {}\n",
    "#for div in unique_divisions:\n",
    "#    a = X_train.Division == div \n",
    "#    b = X_test.Division == div\n",
    "#    X_temp_tr = X_train.loc[a, :]\n",
    "#    X_temp_te = X_test.loc[b, :]\n",
    "#    y_temp_tr = y_train[a]\n",
    "#    y_temp_te = y_test[b]\n",
    "#    results[div] = predictive_pipeline(X_temp_tr, X_temp_te, y_temp_tr, y_temp_te, na_features, non_na_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Random classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.334\n",
      "Training Macro F1 Score: 0.330\n",
      "Testing Accuracy: 0.330\n",
      "Testing Macro F1 Score: 0.326\n"
     ]
    }
   ],
   "source": [
    "# Random classifier\n",
    "y_pred = [random.choice([\"H\", \"A\", \"D\"]) for _ in range(len(y_train))]\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "macro_f1 = f1_score(y_train, y_pred, average='macro')\n",
    "print(f'Training Accuracy: {accuracy:.3f}')\n",
    "print(f'Training Macro F1 Score: {macro_f1:.3f}')\n",
    "\n",
    "y_pred = [random.choice([\"H\", \"A\", \"D\"]) for _ in range(len(y_test))]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.3f}')\n",
    "print(f'Testing Macro F1 Score: {macro_f1:.3f}')\n",
    "\n",
    "#class_report = classification_report(y_test, y_pred)\n",
    "#print('Classification Report:\\n', class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model with engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[~X_train.HWR.isna(),:]\n",
    "X_test = X_test.loc[~X_test.HWR.isna(),:]\n",
    "y_train = y_train[X_train.index.values]\n",
    "y_test = y_test[X_test.index.values]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country            0\n",
       "League             0\n",
       "Division           0\n",
       "Season             0\n",
       "Date               0\n",
       "HomeTeam           0\n",
       "AwayTeam           0\n",
       "AvgHomeOdds        0\n",
       "AvgDrawOdds        0\n",
       "AvgAwayOdds        0\n",
       "swap_needed        0\n",
       "MatchKey           0\n",
       "SeasonKey          0\n",
       "HomeGoals_cum      0\n",
       "HomeShots_cum      0\n",
       "HomeWins_cum       0\n",
       "HomeCorners_cum    0\n",
       "AwayGoals_cum      0\n",
       "AwayShots_cum      0\n",
       "AwayWins_cum       0\n",
       "AwayCorners_cum    0\n",
       "Draws_cum          0\n",
       "matches            0\n",
       "HWR                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.704\n",
      "Training Macro F1 Score: 0.681\n",
      "Testing Accuracy: 0.470\n",
      "Testing Macro F1 Score: 0.418\n"
     ]
    }
   ],
   "source": [
    "features = [\"HWR\"] + [\"AvgHomeOdds\", \"AvgDrawOdds\", \"AvgAwayOdds\"] # + all_stats\n",
    "rf_params = {'n_estimators': 200,\n",
    "   'max_depth': 15,\n",
    "   'min_samples_split': 6,\n",
    "   'n_jobs': 4}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(**rf_params)\n",
    "model.fit(X_train[features], y_train)\n",
    "\n",
    "# Evaluate on train\n",
    "y_pred = model.predict(X_train[features])\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "macro_f1 = f1_score(y_train, y_pred, average='macro')\n",
    "print(f'Training Accuracy: {accuracy:.3f}')\n",
    "print(f'Training Macro F1 Score: {macro_f1:.3f}')\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = model.predict(X_test[features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.3f}')\n",
    "print(f'Testing Macro F1 Score: {macro_f1:.3f}')\n",
    "#class_report = classification_report(y_test, y_pred)\n",
    "#print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.547\n",
      "Training Macro F1 Score: 0.478\n",
      "Testing Accuracy: 0.497\n",
      "Testing Macro F1 Score: 0.423\n"
     ]
    }
   ],
   "source": [
    "#XGboost \n",
    "model = xgb.XGBClassifier(nthread=6,max_depth=5,n_estimators=300, learning_rate=0.075)\n",
    "\n",
    "mapping_dict = {\"H\": 0, \"D\": 2, \"A\": 1}\n",
    "\n",
    "# Map the categorical values to integers\n",
    "y_train_mapped = pd.Series(y_train).map(mapping_dict)\n",
    "y_test_mapped = pd.Series(y_test).map(mapping_dict)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "model.fit(X_train[features], y_train_mapped)\n",
    "\n",
    "# Evaluate train/test\n",
    "y_pred = model.predict(X_train[features])\n",
    "\n",
    "accuracy = accuracy_score(y_train_mapped, y_pred)\n",
    "macro_f1 = f1_score(y_train_mapped, y_pred, average='macro')\n",
    "print(f'Training Accuracy: {accuracy:.3f}')\n",
    "print(f'Training Macro F1 Score: {macro_f1:.3f}')\n",
    "\n",
    "y_pred = model.predict(X_test[features])\n",
    "\n",
    "accuracy = accuracy_score(y_test_mapped, y_pred)\n",
    "macro_f1 = f1_score(y_test_mapped, y_pred, average='macro')\n",
    "print(f'Testing Accuracy: {accuracy:.3f}')\n",
    "print(f'Testing Macro F1 Score: {macro_f1:.3f}')\n",
    "\n",
    "#class_report = classification_report(y_test, y_pred)\n",
    "#print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betting strategy for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_divs = X_test.Division.unique()\n",
    "unique_divs\n",
    "for div in unique_divs:\n",
    "    mask = X_test.Division == div\n",
    "    matches = X_test.loc[mask, :].shape[0]\n",
    "    bet = 10000/matches\n",
    "    X_test.loc[mask, \"bet\"] = bet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"preds\"] = y_pred\n",
    "X_test[\"act\"] = y_test_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bet(row):\n",
    "    if ((row[\"preds\"] == 0) & (row[\"act\"] == 0)):\n",
    "        return (row[\"bet\"]*row[\"AvgHomeOdds\"])\n",
    "\n",
    "    if ((row[\"preds\"] == 2) & (row[\"act\"] == 2)):\n",
    "        return (row[\"bet\"]*row[\"AvgDrawOdds\"])\n",
    "\n",
    "    if ((row[\"preds\"] == 1) & (row[\"act\"] == 1)):\n",
    "        return (row[\"bet\"]*row[\"AvgAwayOdds\"])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"profit\"] = X_test.apply(lambda row: evaluate_bet(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our profit would be: -8486.86 $\n"
     ]
    }
   ],
   "source": [
    "total_profit = round(X_test[\"profit\"].sum()-X_test[\"bet\"].sum(),2)\n",
    "print(\"Our profit would be:\", total_profit, \"$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
